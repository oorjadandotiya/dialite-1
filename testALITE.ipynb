{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.4\n",
      "Table A:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIC Code</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1110</td>\n",
       "      <td>Growing of cereals (except rice), leguminous c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1120</td>\n",
       "      <td>Growing of rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1130</td>\n",
       "      <td>Growing of vegetables and melons, roots and tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1140</td>\n",
       "      <td>Growing of sugar cane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1150</td>\n",
       "      <td>Growing of tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>98000</td>\n",
       "      <td>Residents property management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>98100</td>\n",
       "      <td>Undifferentiated goods-producing activities of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>98200</td>\n",
       "      <td>Undifferentiated service-producing activities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>99000</td>\n",
       "      <td>Activities of extraterritorial organizations a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>99999</td>\n",
       "      <td>Dormant Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SIC Code                                        Description\n",
       "0        1110  Growing of cereals (except rice), leguminous c...\n",
       "1        1120                                    Growing of rice\n",
       "2        1130  Growing of vegetables and melons, roots and tu...\n",
       "3        1140                              Growing of sugar cane\n",
       "4        1150                                 Growing of tobacco\n",
       "..        ...                                                ...\n",
       "726     98000                      Residents property management\n",
       "727     98100  Undifferentiated goods-producing activities of...\n",
       "728     98200  Undifferentiated service-producing activities ...\n",
       "729     99000  Activities of extraterritorial organizations a...\n",
       "730     99999                                    Dormant Company\n",
       "\n",
       "[731 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table B:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accounting/Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advertising/Public Relations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aerospace/Aviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arts/Entertainment/Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Banking/Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business Opportunity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Clerical/Administrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Construction/Facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Consumer Goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Customer Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Education/Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Energy/Utilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Government/Military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hospitality/Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Human Resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Installation/Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Job Search Aids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Law Enforcement/Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Management/Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Manufacturing/Operations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Non-Profit/Volunteer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Pharmaceutical/Biotech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Professional Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>QA/Quality Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Real Estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Restaurant/Food Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Science/Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Skilled Labor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Telecommunications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Transportation/Logistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Industry\n",
       "0              Accounting/Finance\n",
       "1    Advertising/Public Relations\n",
       "2              Aerospace/Aviation\n",
       "3   Arts/Entertainment/Publishing\n",
       "4                      Automotive\n",
       "5                Banking/Mortgage\n",
       "6            Business Development\n",
       "7            Business Opportunity\n",
       "8         Clerical/Administrative\n",
       "9         Construction/Facilities\n",
       "10                 Consumer Goods\n",
       "11               Customer Service\n",
       "12             Education/Training\n",
       "13               Energy/Utilities\n",
       "14                    Engineering\n",
       "15            Government/Military\n",
       "16                          Green\n",
       "17                     Healthcare\n",
       "18             Hospitality/Travel\n",
       "19                Human Resources\n",
       "20       Installation/Maintenance\n",
       "21                      Insurance\n",
       "22                       Internet\n",
       "23                Job Search Aids\n",
       "24       Law Enforcement/Security\n",
       "25                          Legal\n",
       "26           Management/Executive\n",
       "27       Manufacturing/Operations\n",
       "28                      Marketing\n",
       "29           Non-Profit/Volunteer\n",
       "30         Pharmaceutical/Biotech\n",
       "31          Professional Services\n",
       "32             QA/Quality Control\n",
       "33                    Real Estate\n",
       "34        Restaurant/Food Service\n",
       "35                         Retail\n",
       "36                          Sales\n",
       "37               Science/Research\n",
       "38                  Skilled Labor\n",
       "39                     Technology\n",
       "40             Telecommunications\n",
       "41       Transportation/Logistics\n",
       "42                          Other"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Load Your Actual Source Tables\n",
    "# ----------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "print(pd.__version__)\n",
    "\n",
    "# Replace these with your actual file names or paths\n",
    "table_a = pd.read_csv(r\"data\\dat_dialite\\Alphanumeric - Industry\\industry_sic.csv\")\n",
    "table_b = pd.read_csv(r\"data\\dat_dialite\\Alphanumeric - Industry\\industry.csv\")\n",
    "\n",
    "# Preview the tables\n",
    "print(\"Table A:\")\n",
    "display(table_a)\n",
    "\n",
    "print(\"Table B:\")\n",
    "display(table_b)\n",
    "\n",
    "# with open(\"analysis/movies/movies_groundtruth.csv\", 'rb') as f:\n",
    "#     result = chardet.detect(f.read(10000))\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIC Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1110.0</td>\n",
       "      <td>Growing of cereals (except rice), leguminous c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1120.0</td>\n",
       "      <td>Growing of rice</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1130.0</td>\n",
       "      <td>Growing of vegetables and melons, roots and tu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1140.0</td>\n",
       "      <td>Growing of sugar cane</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1150.0</td>\n",
       "      <td>Growing of tobacco</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Skilled Labor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telecommunications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transportation/Logistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>774 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SIC Code                                        Description  \\\n",
       "0      1110.0  Growing of cereals (except rice), leguminous c...   \n",
       "1      1120.0                                    Growing of rice   \n",
       "2      1130.0  Growing of vegetables and melons, roots and tu...   \n",
       "3      1140.0                              Growing of sugar cane   \n",
       "4      1150.0                                 Growing of tobacco   \n",
       "..        ...                                                ...   \n",
       "769       NaN                                                NaN   \n",
       "770       NaN                                                NaN   \n",
       "771       NaN                                                NaN   \n",
       "772       NaN                                                NaN   \n",
       "773       NaN                                                NaN   \n",
       "\n",
       "                     Industry  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "..                        ...  \n",
       "769             Skilled Labor  \n",
       "770                Technology  \n",
       "771        Telecommunications  \n",
       "772  Transportation/Logistics  \n",
       "773                     Other  \n",
       "\n",
       "[774 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALITE Output Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry</th>\n",
       "      <th>sic code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14141.0</td>\n",
       "      <td>manufacture of men's underwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>87200.0</td>\n",
       "      <td>residential care activities for learning diffi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3120.0</td>\n",
       "      <td>freshwater fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28132.0</td>\n",
       "      <td>manufacture of compressors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>84240.0</td>\n",
       "      <td>public order and safety activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>non-profit/volunteer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>management/executive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>real estate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>business development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>774 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 industry  sic code  \\\n",
       "0                     NaN   14141.0   \n",
       "1                     NaN   87200.0   \n",
       "2                     NaN    3120.0   \n",
       "3                     NaN   28132.0   \n",
       "4                     NaN   84240.0   \n",
       "..                    ...       ...   \n",
       "769  non-profit/volunteer       NaN   \n",
       "770  management/executive       NaN   \n",
       "771           real estate       NaN   \n",
       "772           engineering       NaN   \n",
       "773  business development       NaN   \n",
       "\n",
       "                                           description  \n",
       "0                       manufacture of men's underwear  \n",
       "1    residential care activities for learning diffi...  \n",
       "2                                   freshwater fishing  \n",
       "3                           manufacture of compressors  \n",
       "4                   public order and safety activities  \n",
       "..                                                 ...  \n",
       "769                                                NaN  \n",
       "770                                                NaN  \n",
       "771                                                NaN  \n",
       "772                                                NaN  \n",
       "773                                                NaN  \n",
       "\n",
       "[774 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth = pd.read_csv(\n",
    "    r\"data\\dat_dialite\\Alphanumeric - Industry\\ground_industry.csv\",\n",
    "    quotechar='\"',\n",
    "    on_bad_lines='warn', \n",
    ")\n",
    "\n",
    "alite_output = pd.read_csv(\n",
    "    r\"data\\dat_dialite\\Alphanumeric - Industry\\ir_alite_Alphanumeric - Industry-760400.csv\",\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    quotechar='\"',\n",
    "    on_bad_lines='warn',\n",
    "    engine='python'\n",
    ")\n",
    "# Preview the tables\n",
    "print(\"Ground Truth Table:\")\n",
    "display(ground_truth)\n",
    "\n",
    "print(\"ALITE Output Table:\")\n",
    "display(alite_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns: ['cast', 'country', 'date_added', 'description', 'director', 'duration', 'genre', 'rating', 'release_year', 'show_id', 'title', 'type', 'year']\n",
      "True Positives: 38\n",
      "False Positives: 8808\n",
      "False Negatives: 8811\n",
      "\n",
      "Precision: 0.43%\n",
      "Recall:    0.43%\n",
      "F1 Score:  0.43%\n",
      "\n",
      "Rows in ALITE but not in Ground Truth (False Positives):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>description</th>\n",
       "      <th>director</th>\n",
       "      <th>duration</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>release_year</th>\n",
       "      <th>show_id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emraan hashmi, humaima malik, paresh rawal, ka...</td>\n",
       "      <td>india</td>\n",
       "      <td>november 1, 2018</td>\n",
       "      <td>a small-time con man assembles a team to help ...</td>\n",
       "      <td>kunal deshmukh</td>\n",
       "      <td>131 min</td>\n",
       "      <td>missing</td>\n",
       "      <td>tv-14</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>s4457</td>\n",
       "      <td>raja natwarlal</td>\n",
       "      <td>movie</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zoey deutch, halston sage, erica tremblay, log...</td>\n",
       "      <td>united states</td>\n",
       "      <td>june 8, 2020</td>\n",
       "      <td>forced to continually relive the day she dies ...</td>\n",
       "      <td>ry russo-young</td>\n",
       "      <td>98 min</td>\n",
       "      <td>missing</td>\n",
       "      <td>pg-13</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>s2412</td>\n",
       "      <td>before i fall</td>\n",
       "      <td>movie</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k.j. apa, lili reinhart, camila mendes, cole s...</td>\n",
       "      <td>united states</td>\n",
       "      <td>june 19, 2021</td>\n",
       "      <td>while navigating the troubled waters of sex, r...</td>\n",
       "      <td>rob seidenglanz</td>\n",
       "      <td>4 seasons</td>\n",
       "      <td>missing</td>\n",
       "      <td>tv-14</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>s677</td>\n",
       "      <td>riverdale</td>\n",
       "      <td>tv show</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wendell pierce, jurnee smollett-bell, joanne f...</td>\n",
       "      <td>united states</td>\n",
       "      <td>august 25, 2019</td>\n",
       "      <td>after 25 years of searching, a lonely dentist ...</td>\n",
       "      <td>tim rouhana</td>\n",
       "      <td>92 min</td>\n",
       "      <td>missing</td>\n",
       "      <td>tv-ma</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>s7664</td>\n",
       "      <td>one last thing</td>\n",
       "      <td>movie</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amit tandon</td>\n",
       "      <td>india</td>\n",
       "      <td>february 28, 2020</td>\n",
       "      <td>from the death of romance in marriage to the i...</td>\n",
       "      <td>missing</td>\n",
       "      <td>72 min</td>\n",
       "      <td>missing</td>\n",
       "      <td>tv-14</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>s2870</td>\n",
       "      <td>amit tandon: family tandoncies</td>\n",
       "      <td>movie</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>gbenga titiloye, elvina ibru, sharon ooja, osa...</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>october 11, 2019</td>\n",
       "      <td>with a matriarch bent on having a lavish 51st ...</td>\n",
       "      <td>bolanle austen-peters</td>\n",
       "      <td>99 min</td>\n",
       "      <td>missing</td>\n",
       "      <td>tv-14</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>s3432</td>\n",
       "      <td>the bling lagosians</td>\n",
       "      <td>movie</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>luna maya, herjunot ali, sara wijayanto, maria...</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>january 15, 2019</td>\n",
       "      <td>a mother uses her deceased daughterÃ¢Â€Â™s doll a...</td>\n",
       "      <td>rocky soraya</td>\n",
       "      <td>117 min</td>\n",
       "      <td>missing</td>\n",
       "      <td>tv-ma</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>s4196</td>\n",
       "      <td>the doll 2</td>\n",
       "      <td>movie</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8805</th>\n",
       "      <td>chris klein, jon lovitz, chelsey reist, lochly...</td>\n",
       "      <td>united states</td>\n",
       "      <td>december 31, 2019</td>\n",
       "      <td>a rookie lawyer with an emasculating past in b...</td>\n",
       "      <td>jon rosenbaum</td>\n",
       "      <td>90 min</td>\n",
       "      <td>missing</td>\n",
       "      <td>pg-13</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>s3081</td>\n",
       "      <td>benchwarmers 2: breaking balls</td>\n",
       "      <td>movie</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8806</th>\n",
       "      <td>michael stuhlbarg, richard kind, fred melamed,...</td>\n",
       "      <td>united states, united kingdom, france</td>\n",
       "      <td>january 16, 2018</td>\n",
       "      <td>with every aspect of his life unraveling, a je...</td>\n",
       "      <td>ethan coen, joel coen</td>\n",
       "      <td>106 min</td>\n",
       "      <td>missing</td>\n",
       "      <td>r</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>s6058</td>\n",
       "      <td>a serious man</td>\n",
       "      <td>movie</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8807</th>\n",
       "      <td>shannyn sossamon, john beasley, james ransone,...</td>\n",
       "      <td>united states, united kingdom</td>\n",
       "      <td>october 16, 2019</td>\n",
       "      <td>a single mother and her twin sons move into a ...</td>\n",
       "      <td>ciarÃ£Â¡n foy</td>\n",
       "      <td>97 min</td>\n",
       "      <td>missing</td>\n",
       "      <td>r</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>s3422</td>\n",
       "      <td>sinister 2</td>\n",
       "      <td>movie</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8808 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   cast  \\\n",
       "0     emraan hashmi, humaima malik, paresh rawal, ka...   \n",
       "1     zoey deutch, halston sage, erica tremblay, log...   \n",
       "2     k.j. apa, lili reinhart, camila mendes, cole s...   \n",
       "3     wendell pierce, jurnee smollett-bell, joanne f...   \n",
       "4                                           amit tandon   \n",
       "...                                                 ...   \n",
       "8803  gbenga titiloye, elvina ibru, sharon ooja, osa...   \n",
       "8804  luna maya, herjunot ali, sara wijayanto, maria...   \n",
       "8805  chris klein, jon lovitz, chelsey reist, lochly...   \n",
       "8806  michael stuhlbarg, richard kind, fred melamed,...   \n",
       "8807  shannyn sossamon, john beasley, james ransone,...   \n",
       "\n",
       "                                    country         date_added  \\\n",
       "0                                     india   november 1, 2018   \n",
       "1                             united states       june 8, 2020   \n",
       "2                             united states      june 19, 2021   \n",
       "3                             united states    august 25, 2019   \n",
       "4                                     india  february 28, 2020   \n",
       "...                                     ...                ...   \n",
       "8803                                nigeria   october 11, 2019   \n",
       "8804                              indonesia   january 15, 2019   \n",
       "8805                          united states  december 31, 2019   \n",
       "8806  united states, united kingdom, france   january 16, 2018   \n",
       "8807          united states, united kingdom   october 16, 2019   \n",
       "\n",
       "                                            description  \\\n",
       "0     a small-time con man assembles a team to help ...   \n",
       "1     forced to continually relive the day she dies ...   \n",
       "2     while navigating the troubled waters of sex, r...   \n",
       "3     after 25 years of searching, a lonely dentist ...   \n",
       "4     from the death of romance in marriage to the i...   \n",
       "...                                                 ...   \n",
       "8803  with a matriarch bent on having a lavish 51st ...   \n",
       "8804  a mother uses her deceased daughterÃ¢Â€Â™s doll a...   \n",
       "8805  a rookie lawyer with an emasculating past in b...   \n",
       "8806  with every aspect of his life unraveling, a je...   \n",
       "8807  a single mother and her twin sons move into a ...   \n",
       "\n",
       "                   director   duration    genre rating release_year show_id  \\\n",
       "0            kunal deshmukh    131 min  missing  tv-14       2014.0   s4457   \n",
       "1            ry russo-young     98 min  missing  pg-13       2017.0   s2412   \n",
       "2           rob seidenglanz  4 seasons  missing  tv-14       2019.0    s677   \n",
       "3               tim rouhana     92 min  missing  tv-ma       2018.0   s7664   \n",
       "4                   missing     72 min  missing  tv-14       2019.0   s2870   \n",
       "...                     ...        ...      ...    ...          ...     ...   \n",
       "8803  bolanle austen-peters     99 min  missing  tv-14       2019.0   s3432   \n",
       "8804           rocky soraya    117 min  missing  tv-ma       2017.0   s4196   \n",
       "8805          jon rosenbaum     90 min  missing  pg-13       2019.0   s3081   \n",
       "8806  ethan coen, joel coen    106 min  missing      r       2009.0   s6058   \n",
       "8807            ciarÃ£Â¡n foy     97 min  missing      r       2015.0   s3422   \n",
       "\n",
       "                               title     type     year  \n",
       "0                     raja natwarlal    movie  missing  \n",
       "1                      before i fall    movie  missing  \n",
       "2                          riverdale  tv show  missing  \n",
       "3                     one last thing    movie  missing  \n",
       "4     amit tandon: family tandoncies    movie  missing  \n",
       "...                              ...      ...      ...  \n",
       "8803             the bling lagosians    movie  missing  \n",
       "8804                      the doll 2    movie  missing  \n",
       "8805  benchwarmers 2: breaking balls    movie  missing  \n",
       "8806                   a serious man    movie  missing  \n",
       "8807                      sinister 2    movie  missing  \n",
       "\n",
       "[8808 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows in Ground Truth but missing from ALITE (False Negatives):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>description</th>\n",
       "      <th>director</th>\n",
       "      <th>duration</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>release_year</th>\n",
       "      <th>show_id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>sangeeth sivan</td>\n",
       "      <td>missing</td>\n",
       "      <td>comedies</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>kyaa kool hai hum</td>\n",
       "      <td>missing</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>matï¿½as gueilburt</td>\n",
       "      <td>missing</td>\n",
       "      <td>documentaries</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>patria</td>\n",
       "      <td>missing</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>jami</td>\n",
       "      <td>missing</td>\n",
       "      <td>dramas</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>moor</td>\n",
       "      <td>missing</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>stand-up comedy &amp; talk shows</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>chelsea</td>\n",
       "      <td>missing</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>tv action &amp; adventure</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>warrior nun</td>\n",
       "      <td>missing</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8806</th>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>ashwin saravanan</td>\n",
       "      <td>missing</td>\n",
       "      <td>horror movies</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>game over (telugu version)</td>\n",
       "      <td>missing</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8807</th>\n",
       "      <td>sophia isabella</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>kids' tv</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>s2041</td>\n",
       "      <td>transformers: cyberverse</td>\n",
       "      <td>tv show</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8808</th>\n",
       "      <td>vir das</td>\n",
       "      <td>united states</td>\n",
       "      <td>25-04-2017</td>\n",
       "      <td>comedian vir das tackles nationalism</td>\n",
       "      <td>marcus raboy</td>\n",
       "      <td>66 min</td>\n",
       "      <td>stand-up comedy</td>\n",
       "      <td>tv-ma</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>s5519</td>\n",
       "      <td>vir das: abroad understanding</td>\n",
       "      <td>movie</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8809</th>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>jose gomez</td>\n",
       "      <td>missing</td>\n",
       "      <td>documentaries</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>not a game</td>\n",
       "      <td>missing</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8810</th>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>noam murro</td>\n",
       "      <td>missing</td>\n",
       "      <td>comedies</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>smart people</td>\n",
       "      <td>missing</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8811 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cast        country  date_added  \\\n",
       "0             missing        missing     missing   \n",
       "1             missing        missing     missing   \n",
       "2             missing        missing     missing   \n",
       "3             missing        missing     missing   \n",
       "4             missing        missing     missing   \n",
       "...               ...            ...         ...   \n",
       "8806          missing        missing     missing   \n",
       "8807  sophia isabella        missing     missing   \n",
       "8808          vir das  united states  25-04-2017   \n",
       "8809          missing        missing     missing   \n",
       "8810          missing        missing     missing   \n",
       "\n",
       "                               description          director duration  \\\n",
       "0                                  missing    sangeeth sivan  missing   \n",
       "1                                  missing  matï¿½as gueilburt  missing   \n",
       "2                                  missing              jami  missing   \n",
       "3                                  missing           missing  missing   \n",
       "4                                  missing           missing  missing   \n",
       "...                                    ...               ...      ...   \n",
       "8806                               missing  ashwin saravanan  missing   \n",
       "8807                               missing           missing  missing   \n",
       "8808  comedian vir das tackles nationalism      marcus raboy   66 min   \n",
       "8809                               missing        jose gomez  missing   \n",
       "8810                               missing        noam murro  missing   \n",
       "\n",
       "                             genre   rating release_year  show_id  \\\n",
       "0                         comedies  missing      missing  missing   \n",
       "1                    documentaries  missing      missing  missing   \n",
       "2                           dramas  missing      missing  missing   \n",
       "3     stand-up comedy & talk shows  missing      missing  missing   \n",
       "4            tv action & adventure  missing      missing  missing   \n",
       "...                            ...      ...          ...      ...   \n",
       "8806                 horror movies  missing      missing  missing   \n",
       "8807                      kids' tv  missing      missing    s2041   \n",
       "8808               stand-up comedy    tv-ma       2017.0    s5519   \n",
       "8809                 documentaries  missing      missing  missing   \n",
       "8810                      comedies  missing      missing  missing   \n",
       "\n",
       "                              title     type    year  \n",
       "0                 kyaa kool hai hum  missing  2005.0  \n",
       "1                            patria  missing  2019.0  \n",
       "2                              moor  missing  2015.0  \n",
       "3                           chelsea  missing  2017.0  \n",
       "4                       warrior nun  missing  2020.0  \n",
       "...                             ...      ...     ...  \n",
       "8806     game over (telugu version)  missing  2019.0  \n",
       "8807       transformers: cyberverse  tv show  2020.0  \n",
       "8808  vir das: abroad understanding    movie  2017.0  \n",
       "8809                     not a game  missing  2020.0  \n",
       "8810                   smart people  missing  2008.0  \n",
       "\n",
       "[8811 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from IPython.display import display\n",
    "\n",
    "# # Load the datasets\n",
    "# ground_truth = pd.read_csv(r\"data\\dat_dialite\\Alphanumeric - Industry\\ground_industry.csv\")\n",
    "# alite_output = pd.read_csv(r\"data\\dat_dialite\\Alphanumeric - Industry\\ir_alite_Alphanumeric - Industry-760400.csv\")\n",
    "\n",
    "# # Step 1: Standardise column names\n",
    "# ground_truth.columns = ground_truth.columns.str.strip().str.lower()\n",
    "# alite_output.columns = alite_output.columns.str.strip().str.lower()\n",
    "\n",
    "# # Step 2: Identify common columns\n",
    "# common_cols = list(set(ground_truth.columns) & set(alite_output.columns))\n",
    "# print(f\"Common columns: {common_cols}\")\n",
    "\n",
    "# # Step 3: Clean & normalise string values in those columns\n",
    "# def clean_df(df):\n",
    "#     return df[common_cols].dropna().astype(str).apply(lambda x: x.str.strip().str.lower())\n",
    "\n",
    "# gt_clean = clean_df(ground_truth)\n",
    "# ao_clean = clean_df(alite_output)\n",
    "\n",
    "# print(\"Cleaned Ground Truth Table:\")\n",
    "# display(gt_clean.head())\n",
    "# print(\"Cleaned ALITE Output Table:\")    \n",
    "# display(ao_clean.head())\n",
    "\n",
    "# # Step 4: Convert rows to sets of values (per row), then sets of sets\n",
    "# gt_sets = set(frozenset(row) for row in gt_clean.values.tolist())\n",
    "# ao_sets = set(frozenset(row) for row in ao_clean.values.tolist())\n",
    "\n",
    "# # Step 5: Calculate exact row matches\n",
    "# tp = gt_sets & ao_sets  # True Positives\n",
    "# print(f\"True Positives: {len(tp)}\")\n",
    "# fp = ao_sets - gt_sets  # False Positives\n",
    "# print(f\"False Positives: {len(fp)}\")\n",
    "# fn = gt_sets - ao_sets  # False Negatives\n",
    "# print(f\"False Negatives: {len(fn)}\")\n",
    "\n",
    "# # Step 6: Metrics\n",
    "# precision = len(tp) / (len(tp) + len(fp)) if (len(tp) + len(fp)) > 0 else 0\n",
    "# recall = len(tp) / (len(tp) + len(fn)) if (len(tp) + len(fn)) > 0 else 0\n",
    "# f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# # Step 7: Display metrics\n",
    "# print(f\"Set-Based Row Match Precision: {precision:.2%}\")\n",
    "# print(f\"Set-Based Row Match Recall:    {recall:.2%}\")\n",
    "# print(f\"Set-Based Row Match F1 Score:  {f1:.2%}\")\n",
    "\n",
    "# # Step 9: Display mismatches\n",
    "# fp_df = pd.DataFrame([list(s) for s in fp])\n",
    "# fn_df = pd.DataFrame([list(s) for s in fn])\n",
    "\n",
    "# print(\"\\n Rows in ALITE but not in Ground Truth (False Positives):\")\n",
    "# display(fp_df)\n",
    "\n",
    "# print(\"\\n Rows in Ground Truth but missing from ALITE (False Negatives):\")\n",
    "# display(fn_df)\n",
    "\n",
    "# # Step 10: Save metrics\n",
    "# metrics = pd.DataFrame({\n",
    "#     'Metric': ['Precision', 'Recall', 'F1 Score'],\n",
    "#     'Value': [precision, recall, f1]\n",
    "# })\n",
    "# metrics.to_csv(\"analysis/set_row_match_metrics.csv\", index=False)\n",
    "\n",
    "#--------------------------code thatt works--------------------------\n",
    "# import pandas as pd\n",
    "# from IPython.display import display\n",
    "\n",
    "# # Load the datasets\n",
    "# ground_truth = pd.read_csv(r\"data\\dat_dialite\\Alphanumeric - Industry\\ground_industry.csv\")\n",
    "# alite_output = pd.read_csv(r\"data\\dat_dialite\\Alphanumeric - Industry\\ir_alite_Alphanumeric - Industry-760400.csv\")\n",
    "\n",
    "# # Step 1: Standardise column names\n",
    "# ground_truth.columns = ground_truth.columns.str.strip().str.lower()\n",
    "# alite_output.columns = alite_output.columns.str.strip().str.lower()\n",
    "\n",
    "# # Step 2: Identify common columns\n",
    "# common_cols = sorted(set(ground_truth.columns) & set(alite_output.columns))\n",
    "# print(\"Common columns:\", common_cols)\n",
    "\n",
    "# # Step 3: Clean and flatten each row into a tuple of values\n",
    "# def clean_and_flatten(df):\n",
    "#     return [\n",
    "#         tuple(\n",
    "#             str(x).strip().lower() if pd.notna(x) else \"missing\"\n",
    "#             for x in row\n",
    "#         )\n",
    "#         for row in df[common_cols].values.tolist()\n",
    "#     ]\n",
    "\n",
    "# gt_rows = set(clean_and_flatten(ground_truth))\n",
    "# ao_rows = set(clean_and_flatten(alite_output))\n",
    "\n",
    "# # Step 4: Compare the sets of rows\n",
    "# tp = gt_rows & ao_rows  # True Positives\n",
    "# fp = ao_rows - gt_rows  # False Positives\n",
    "# fn = gt_rows - ao_rows  # False Negatives\n",
    "\n",
    "# print(\"True Positives:\", len(tp))\n",
    "# print(\"False Positives:\", len(fp))\n",
    "# print(\"False Negatives:\", len(fn))\n",
    "\n",
    "# # Step 5: Compute metrics\n",
    "# precision = len(tp) / (len(tp) + len(fp)) if (len(tp) + len(fp)) > 0 else 0\n",
    "# recall = len(tp) / (len(tp) + len(fn)) if (len(tp) + len(fn)) > 0 else 0\n",
    "# f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# print(\"\\nPrecision: {:.2%}\".format(precision))\n",
    "# print(\"Recall:    {:.2%}\".format(recall))\n",
    "# print(\"F1 Score:  {:.2%}\".format(f1))\n",
    "\n",
    "# # Step 6: Display mismatches\n",
    "# fp_df = pd.DataFrame(list(fp), columns=common_cols)\n",
    "# fn_df = pd.DataFrame(list(fn), columns=common_cols)\n",
    "\n",
    "# print(\"\\nRows in ALITE but not in Ground Truth (False Positives):\")\n",
    "# display(fp_df)\n",
    "\n",
    "# print(\"\\nRows in Ground Truth but missing from ALITE (False Negatives):\")\n",
    "# display(fn_df)\n",
    "\n",
    "# # Step 7: Save metrics\n",
    "# metrics = pd.DataFrame({\n",
    "#     'Metric': ['Precision', 'Recall', 'F1 Score'],\n",
    "#     'Value': [precision, recall, f1]\n",
    "# })\n",
    "# metrics.to_csv(\"analysis/set_row_match_metrics.csv\", index=False)\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the datasets\n",
    "ground_truth = pd.read_csv(r\"data\\dat_dialite\\Alphanumeric - Movies\\movies_groundtruth.csv\")\n",
    "alite_output = pd.read_csv(r\"data\\dat_dialite\\Alphanumeric - Movies\\integratedALITEmovies.csv\")\n",
    "\n",
    "# Step 1: Standardise column names\n",
    "ground_truth.columns = ground_truth.columns.str.strip().str.lower()\n",
    "alite_output.columns = alite_output.columns.str.strip().str.lower()\n",
    "\n",
    "# Step 2: Identify common columns\n",
    "common_cols = sorted(set(ground_truth.columns) & set(alite_output.columns))\n",
    "print(\"Common columns:\", common_cols)\n",
    "\n",
    "# Step 3: Clean and flatten each row into a tuple of values\n",
    "def clean_and_flatten(df):\n",
    "    return [\n",
    "        tuple(\n",
    "            str(x).strip().lower() if pd.notna(x) else \"missing\"\n",
    "            for x in row\n",
    "        )\n",
    "        for row in df[common_cols].values.tolist()\n",
    "    ]\n",
    "\n",
    "gt_rows = set(clean_and_flatten(ground_truth))\n",
    "ao_rows = set(clean_and_flatten(alite_output))\n",
    "\n",
    "# Step 4: Compare the sets of rows\n",
    "tp = gt_rows & ao_rows  # True Positives\n",
    "fp = ao_rows - gt_rows  # False Positives\n",
    "fn = gt_rows - ao_rows  # False Negatives\n",
    "\n",
    "print(\"True Positives:\", len(tp))\n",
    "print(\"False Positives:\", len(fp))\n",
    "print(\"False Negatives:\", len(fn))\n",
    "\n",
    "# Step 5: Compute metrics\n",
    "precision = len(tp) / (len(tp) + len(fp)) if (len(tp) + len(fp)) > 0 else 0\n",
    "recall = len(tp) / (len(tp) + len(fn)) if (len(tp) + len(fn)) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(\"\\nPrecision: {:.2%}\".format(precision))\n",
    "print(\"Recall:    {:.2%}\".format(recall))\n",
    "print(\"F1 Score:  {:.2%}\".format(f1))\n",
    "\n",
    "# Step 6: Display mismatches safely\n",
    "fp_rows = [list(row) for row in fp if len(row) == len(common_cols)]\n",
    "fn_rows = [list(row) for row in fn if len(row) == len(common_cols)]\n",
    "\n",
    "fp_df = pd.DataFrame(fp_rows, columns=common_cols)\n",
    "fn_df = pd.DataFrame(fn_rows, columns=common_cols)\n",
    "\n",
    "print(\"\\nRows in ALITE but not in Ground Truth (False Positives):\")\n",
    "display(fp_df)\n",
    "\n",
    "print(\"\\nRows in Ground Truth but missing from ALITE (False Negatives):\")\n",
    "display(fn_df)\n",
    "\n",
    "# Step 7: Save metrics\n",
    "metrics = pd.DataFrame({\n",
    "    'Metric': ['Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [precision, recall, f1]\n",
    "})\n",
    "metrics.to_csv(\"analysis/set_row_match_metrics.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns for comparison: ['description']\n"
     ]
    }
   ],
   "source": [
    "# # Standardise column names\n",
    "# ground_truth.columns = ground_truth.columns.str.strip().str.lower()\n",
    "# alite_output.columns = alite_output.columns.str.strip().str.lower()\n",
    "\n",
    "# common_cols = list(set(ground_truth.columns) & set(alite_output.columns))\n",
    "\n",
    "# # Set index for matching\n",
    "# ground_truth.reset_index(inplace=True)\n",
    "# alite_output.reset_index(inplace=True)\n",
    "\n",
    "# ground_truth.set_index(\"title\", inplace=True)\n",
    "# alite_output.set_index(\"title\", inplace=True)\n",
    "\n",
    "# # Remove 'title' from common_cols (because it's now the index)\n",
    "# if 'title' in common_cols:\n",
    "#     common_cols.remove('title')\n",
    "\n",
    "# print(\"Common columns for comparison:\", common_cols)\n",
    "\n",
    "# Standardise column names\n",
    "ground_truth.columns = ground_truth.columns.str.strip().str.lower()\n",
    "alite_output.columns = alite_output.columns.str.strip().str.lower()\n",
    "\n",
    "# Identify common columns\n",
    "common_cols = list(set(ground_truth.columns) & set(alite_output.columns))\n",
    "\n",
    "# Create composite key: product_id + user_id\n",
    "ground_truth['composite_key'] = ground_truth['sic code'].astype(str) + \"_\" + ground_truth['industry'].astype(str)\n",
    "alite_output['composite_key'] = alite_output['sic code'].astype(str) + \"_\" + alite_output['industry'].astype(str)\n",
    "\n",
    "# Set composite key as index\n",
    "ground_truth.set_index('composite_key', inplace=True)\n",
    "alite_output.set_index('composite_key', inplace=True)\n",
    "\n",
    "# Remove fields used in key from comparison\n",
    "for col in ['composite_key', 'sic code', 'industry']:\n",
    "    if col in common_cols:\n",
    "        common_cols.remove(col)\n",
    "\n",
    "print(\"Common columns for comparison:\", common_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description    100.0\n",
      "dtype: float64\n",
      "\n",
      "Overall Integration Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Only keep rows with matching titles\n",
    "matched_titles = ground_truth.index.intersection(alite_output.index)\n",
    "\n",
    "# Subset both datasets using matched titles and common columns\n",
    "gt_raw = ground_truth.loc[matched_titles, common_cols]\n",
    "alite_raw = alite_output.loc[matched_titles, common_cols]\n",
    "\n",
    "gt_raw.columns = gt_raw.columns.str.strip().str.lower()\n",
    "alite_raw.columns = alite_raw.columns.str.strip().str.lower()\n",
    "\n",
    "# Define a normalisation function (strip strings and lowercase)\n",
    "def normalize(df):\n",
    "    return df.applymap(lambda x: str(x).strip().lower() if isinstance(x, str) else x)\n",
    "\n",
    "# Apply normalization to both subsets\n",
    "gt_subset = normalize(gt_raw)\n",
    "alite_subset = normalize(alite_raw)\n",
    "\n",
    "gt_subset.columns = gt_subset.columns.str.strip().str.lower()\n",
    "alite_subset.columns = alite_subset.columns.str.strip().str.lower()\n",
    "\n",
    "# Compare only common columns for those matched titles\n",
    "comparison = gt_subset.eq(alite_subset)\n",
    "\n",
    "# Accuracy per column\n",
    "accuracy = comparison.mean() * 100\n",
    "print(accuracy)\n",
    "\n",
    "# Overall integration accuracy\n",
    "total_accuracy = comparison.stack().mean() * 100\n",
    "print(f\"\\nOverall Integration Accuracy: {total_accuracy:.2f}%\")\n",
    "\n",
    "# Save the comparison result to a CSV file\n",
    "comparison.to_csv(\"analysis/comparison_result.csv\", index=True)\n",
    "# Save the accuracy results to a CSV file       \n",
    "accuracy.to_csv(\"analysis/accuracy_results.csv\", header=[\"Accuracy (%)\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_titles = ground_truth.index.intersection(alite_output.index)\n",
    "\n",
    "gt_subset = ground_truth.loc[matched_titles, common_cols]\n",
    "alite_subset = alite_output.loc[matched_titles, common_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compare values\n",
    "matches = gt_subset.eq(alite_subset)\n",
    "tp = matches.sum().sum()  # Correct matches\n",
    "\n",
    "# False Positives: ALITE has a value â‰  ground truth\n",
    "fp = (~matches & alite_subset.notna()).sum().sum()\n",
    "\n",
    "# False Negatives: Ground truth has a value but ALITE is missing\n",
    "fn = (~matches & gt_subset.notna() & alite_subset.isna()).sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.41%\n",
      "Recall:    100.00%\n",
      "F1 Score:  0.82%\n"
     ]
    }
   ],
   "source": [
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall:    {recall:.2%}\")\n",
    "print(f\"F1 Score:  {f1:.2%}\")\n",
    "\n",
    "#save the precision, recall, and F1 score to a CSV file\n",
    "metrics = pd.DataFrame({\n",
    "    'Metric': ['Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [precision, recall, f1]\n",
    "})\n",
    "metrics.to_csv(\"analysis/integration_metrics.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
